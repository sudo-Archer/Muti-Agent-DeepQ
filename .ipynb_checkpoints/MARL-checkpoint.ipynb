{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b3d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from stage.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import stage\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from sty import fg, bg, ef, rs\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098fc89",
   "metadata": {},
   "source": [
    "## Play Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f84026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Play_random:\n",
    "    def __init__(self,env: stage.Environment):\n",
    "        self.env = env\n",
    "        pass\n",
    "    def play(self, limit = 500):\n",
    "        \n",
    "        env = self.env\n",
    "        frames = []\n",
    "        time = 0\n",
    "        env.reset()\n",
    "        agents_n = len(self.env.agents)\n",
    "\n",
    "        while not env.isDone():\n",
    "            agent = time % agents_n\n",
    "    \n",
    "            state = env.getState()\n",
    "        \n",
    "            action = random.randint(0, 4)\n",
    "            \n",
    "            time += 1\n",
    "    \n",
    "            env.nextStep(agent, action)\n",
    "    \n",
    "            frames.append(env.render())\n",
    "    \n",
    "            if time > limit:\n",
    "                break\n",
    "        return frames\n",
    "    def show(self):\n",
    "        frames = self.play()\n",
    "        stage.print_frames(frames)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13449ac7",
   "metadata": {},
   "source": [
    "## Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef12a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_table:\n",
    "    def __init__(self, actionSize: int):\n",
    "        self.table = {}\n",
    "        self.actionSize = actionSize\n",
    "        \n",
    "    def add(self, state):\n",
    "        if state not in self.table:\n",
    "            self.table[state] = np.random.randn(self.actionSize)*0.001\n",
    "    def get(self, state, action):\n",
    "        self.add(state)\n",
    "        return self.table[state][action]\n",
    "        \n",
    "    def getMax(self, state):\n",
    "        self.add(state)\n",
    "        return np.argmax(self.table[state])\n",
    "    \n",
    "    def getMin(self, state):\n",
    "        self.add(state)\n",
    "        return np.argmin(self.table[state])\n",
    "    def maxVal(self, state):\n",
    "        self.add(state)\n",
    "        return np.max(self.table[state])\n",
    "\n",
    "    def setVal(self, state, action, set_as):\n",
    "        self.table[state][action] = set_as\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74444a41",
   "metadata": {},
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16a51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicQlearning:\n",
    "    def __init__(self,env: stage.Environment):\n",
    "        self.env = env\n",
    "        self.agent_n = len(env.agents)\n",
    "        self.q_tables = []\n",
    "        for i in range(self.agent_n):\n",
    "            self.q_tables.append(Q_table(5))\n",
    "        \n",
    "    def train(self, alpha = 0.1, gamma = 0.6, epsilon = 0.1, epochs = 1_000, cap = 2_000):\n",
    "        \n",
    "        env = self.env\n",
    "        env.reset()\n",
    "        totalTime = 0\n",
    "        for i in range(1, epochs):\n",
    "            env.reset()\n",
    "            time = 0\n",
    "\n",
    "            while not env.isDone():\n",
    "                \n",
    "                time += 1\n",
    "                \n",
    "                if time > cap:\n",
    "                    break\n",
    "                \n",
    "                # Forward Prop\n",
    "                for agent in range(self.agent_n):\n",
    "                    \n",
    "                    state = env.agents[agent].getPos()\n",
    "                    q_table = self.q_tables[agent]\n",
    "\n",
    "                    if random.uniform(0, 1) < epsilon:\n",
    "                        action = random.randint(0, 4) # Explore\n",
    "                    else:\n",
    "                        action = q_table.getMax(state) # Exploit learned valued\n",
    "\n",
    "                    env.nextStep(agent, action)\n",
    "                \n",
    "    \n",
    "                    reward = env.reward(agent)\n",
    "                                \n",
    "                    next_state = env.agents[agent].getPos()\n",
    "                    old_value = q_table.get(state, action)\n",
    "                    \n",
    "                    next_max = q_table.maxVal(next_state)\n",
    "                    \n",
    "                    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * (next_max))\n",
    "                    \n",
    "                    q_table.setVal(state, action, new_value)\n",
    "                    \n",
    "                \n",
    "            \n",
    "            totalTime += time\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Episode: {i}\")\n",
    "                print(f\"Time: {totalTime/100}\")\n",
    "                totalTime = 0\n",
    "\n",
    "\n",
    "        print(\"Training Finished!\")\n",
    "    def play(self, cap = 2_000, epsilon = 0.1):\n",
    "        \n",
    "        env = self.env\n",
    "        frames = []\n",
    "        time = 0\n",
    "        env.reset()\n",
    "        while not env.isDone():\n",
    "            # Forward Prop\n",
    "            for agent in range(self.agent_n):\n",
    "                    \n",
    "                state = env.agents[agent].getPos()\n",
    "                q_table = self.q_tables[agent]\n",
    "\n",
    "                if random.uniform(0, 1) < epsilon:\n",
    "                    action = random.randint(0, 4) # Explore\n",
    "                else:\n",
    "                    action = q_table.getMax(state) # Exploit learned valued\n",
    "\n",
    "                env.nextStep(agent, action)\n",
    "    \n",
    "            frames.append(env.render())\n",
    "    \n",
    "            if time > cap:\n",
    "                break\n",
    "        return frames\n",
    "    \n",
    "    def show(self, cap = 2_000, epsilon = 0.1):\n",
    "        frames = self.play(cap, epsilon)\n",
    "        stage.print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1abe294",
   "metadata": {},
   "source": [
    "## Mean-field RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a485ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanField:\n",
    "    def __init__(self,env: stage.Environment):\n",
    "        self.env = env\n",
    "        self.agent_n = len(env.agents)\n",
    "        self.q_tables = []\n",
    "        for i in range(self.agent_n):\n",
    "            self.q_tables.append(Q_table(5))\n",
    "        \n",
    "    def train(self, alpha = 0.1, gamma = 0.6, epsilon = 0.1, epochs = 1_000, cap = 2_000):\n",
    "        \n",
    "        env = self.env\n",
    "        env.reset()\n",
    "        totalTime = 0\n",
    "        for i in range(1, epochs):\n",
    "            env.reset()\n",
    "            time = 0\n",
    "\n",
    "            while not env.isDone():\n",
    "                \n",
    "                time += 1\n",
    "                \n",
    "                if time > cap:\n",
    "                    break\n",
    "                \n",
    "                # Forward Prop\n",
    "                states_action = []\n",
    "                meanVal = 0\n",
    "                for agent in range(self.agent_n):\n",
    "                    \n",
    "                    state = env.getState()\n",
    "                    q_table = self.q_tables[agent]\n",
    "\n",
    "                    if random.uniform(0, 1) < epsilon:\n",
    "                        action = random.randint(0, 4) # Explore\n",
    "                    else:\n",
    "                        action = q_table.getMax(state) # Exploit learned valued\n",
    "\n",
    "                    env.nextStep(agent, action)\n",
    "                    states_action.append((state, action))\n",
    "                    \n",
    "                    # calculate mean Val\n",
    "                    next_state = env.getState()\n",
    "                    meanVal += q_table.maxVal(next_state)\n",
    "                \n",
    "                # Back prop\n",
    "                for agent in range(self.agent_n):\n",
    "                    \n",
    "                    q_table = self.q_tables[agent]\n",
    "                    state, action = states_action[agent]\n",
    "                    \n",
    "                    reward = env.reward(agent)   \n",
    "                    \n",
    "                    old_value = q_table.get(state, action)\n",
    "                    \n",
    "                    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * (meanVal/self.agent_n))\n",
    "                    \n",
    "                    q_table.setVal(state, action, new_value)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            totalTime += time\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Episode: {i}\")\n",
    "                print(f\"Time: {totalTime/100}\")\n",
    "                totalTime = 0\n",
    "\n",
    "\n",
    "        print(\"Training Finished!\")\n",
    "    def play(self, cap = 2_000, epsilon = 0.1):\n",
    "        \n",
    "        env = self.env\n",
    "        frames = []\n",
    "        time = 0\n",
    "        env.reset()\n",
    "        while not env.isDone():\n",
    "            # Forward Prop\n",
    "            for agent in range(self.agent_n):\n",
    "                time +=1\n",
    "                    \n",
    "                state = env.getState()\n",
    "                q_table = self.q_tables[agent]\n",
    "\n",
    "                if random.uniform(0, 1) < epsilon:\n",
    "                    action = random.randint(0, 4) # Explore\n",
    "                else:\n",
    "                    action = q_table.getMax(state) # Exploit learned valued\n",
    "\n",
    "                env.nextStep(agent, action)\n",
    "    \n",
    "            frames.append(env.render())\n",
    "    \n",
    "            if time > cap:\n",
    "                break\n",
    "        return frames\n",
    "    \n",
    "    def show(self, cap = 2_000, epsilon = 0.1):\n",
    "        frames = self.play(cap, epsilon)\n",
    "        stage.print_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574df20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b852f7",
   "metadata": {},
   "source": [
    "https://www.ijcai.org/proceedings/2021/0070.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
